{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT_ONE has been processed!\n",
      "LEFT_TWO has been processed!\n",
      "LEFT_THREE has been processed!\n",
      "RIGHT_ONE has been processed!\n",
      "RIGHT_TWO has been processed!\n",
      "RIGHT_THREE has been processed!\n"
     ]
    }
   ],
   "source": [
    "# Folders, named after the file label\n",
    "labels = [\"LEFT_ONE\", \"LEFT_TWO\", \"LEFT_THREE\",\n",
    "          \"RIGHT_ONE\", \"RIGHT_TWO\", \"RIGHT_THREE\"]\n",
    "\n",
    "# Store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Go through each label\n",
    "for label in labels:\n",
    "    # Go through each file in folder\n",
    "    folder_path = os.listdir(label)\n",
    "\n",
    "    for file_name in folder_path:\n",
    "        # Read the file\n",
    "        df = pd.read_parquet(f\"{label}/{file_name}\")\n",
    "        df[\"sign\"] = labels.index(label)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    print(f\"{label} has been processed!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, LeftX to RightY\n",
      "Data columns (total 22 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4 non-null      float64\n",
      " 1   1       4 non-null      float64\n",
      " 2   2       4 non-null      float64\n",
      " 3   3       4 non-null      float64\n",
      " 4   4       4 non-null      float64\n",
      " 5   5       4 non-null      float64\n",
      " 6   6       4 non-null      float64\n",
      " 7   7       4 non-null      float64\n",
      " 8   8       4 non-null      float64\n",
      " 9   9       4 non-null      float64\n",
      " 10  10      4 non-null      float64\n",
      " 11  11      4 non-null      float64\n",
      " 12  12      4 non-null      float64\n",
      " 13  13      4 non-null      float64\n",
      " 14  14      4 non-null      float64\n",
      " 15  15      4 non-null      float64\n",
      " 16  16      4 non-null      float64\n",
      " 17  17      4 non-null      float64\n",
      " 18  18      4 non-null      float64\n",
      " 19  19      4 non-null      float64\n",
      " 20  20      4 non-null      float64\n",
      " 21  sign    4 non-null      int64  \n",
      "dtypes: float64(21), int64(1)\n",
      "memory usage: 736.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dataframes[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LeftX</th>\n",
       "      <td>0.323437</td>\n",
       "      <td>0.365625</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.415625</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.346875</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.346875</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.251563</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>0.223438</td>\n",
       "      <td>0.279687</td>\n",
       "      <td>0.303125</td>\n",
       "      <td>0.301563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RightX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeftY</th>\n",
       "      <td>1.008333</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.952083</td>\n",
       "      <td>0.922917</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1.031250</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.964583</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>1.037500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RightY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "LeftX   0.323437  0.365625  0.400000  0.415625  0.396875  0.346875  0.343750   \n",
       "RightX  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "LeftY   1.008333  0.989583  0.952083  0.922917  0.910417  0.822917  0.722917   \n",
       "RightY  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               7         8         9  ...        12        13        14  \\\n",
       "LeftX   0.346875  0.343750  0.290625  ...  0.381250  0.251563  0.320312   \n",
       "RightX  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "LeftY   0.650000  0.589583  0.833333  ...  0.983333  0.875000  0.906250   \n",
       "RightY  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "              15        16        17        18        19        20  sign  \n",
       "LeftX   0.343750  0.340625  0.223438  0.279687  0.303125  0.301563     0  \n",
       "RightX  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000     0  \n",
       "LeftY   0.991667  1.031250  0.935417  0.964583  1.016667  1.037500     0  \n",
       "RightY  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000     0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364\n"
     ]
    }
   ],
   "source": [
    "# Define empty lists to store features and labels\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "for dataframe in dataframes:\n",
    "    # Extract features (all columns except the last one) and labels (last column)\n",
    "    features = dataframe.iloc[:, :-1].values\n",
    "    labels = dataframe.iloc[:, -1].values\n",
    "\n",
    "    features_list.append(features)\n",
    "    labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack features and labels into NumPy arrays\n",
    "features_array = np.vstack(features_list)\n",
    "labels_array = np.hstack(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor = tf.convert_to_tensor(features_array, dtype=tf.float32)\n",
    "labels_tensor = tf.convert_to_tensor(labels_array, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.6187 - accuracy: 0.3115 - val_loss: 4.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1.4407 - accuracy: 0.4067 - val_loss: 5.8410 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1.3221 - accuracy: 0.4425 - val_loss: 6.7740 - val_accuracy: 0.0037\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 994us/step - loss: 1.2457 - accuracy: 0.4499 - val_loss: 7.4673 - val_accuracy: 0.0428\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 989us/step - loss: 1.1909 - accuracy: 0.4677 - val_loss: 8.0209 - val_accuracy: 0.0201\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1.1513 - accuracy: 0.4820 - val_loss: 8.5892 - val_accuracy: 0.0328\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1.1208 - accuracy: 0.4952 - val_loss: 9.0825 - val_accuracy: 0.0328\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 996us/step - loss: 1.0978 - accuracy: 0.4999 - val_loss: 9.4645 - val_accuracy: 0.0328\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 978us/step - loss: 1.0766 - accuracy: 0.5054 - val_loss: 9.9040 - val_accuracy: 0.0391\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 987us/step - loss: 1.0598 - accuracy: 0.5058 - val_loss: 10.2238 - val_accuracy: 0.0423\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 979us/step - loss: 1.0459 - accuracy: 0.5114 - val_loss: 10.5311 - val_accuracy: 0.0423\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 990us/step - loss: 1.0308 - accuracy: 0.5210 - val_loss: 10.9729 - val_accuracy: 0.0412\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 986us/step - loss: 1.0197 - accuracy: 0.5234 - val_loss: 11.2351 - val_accuracy: 0.0407\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 991us/step - loss: 1.0065 - accuracy: 0.5307 - val_loss: 11.5985 - val_accuracy: 0.0418\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 993us/step - loss: 0.9972 - accuracy: 0.5290 - val_loss: 11.8860 - val_accuracy: 0.0396\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 980us/step - loss: 0.9877 - accuracy: 0.5385 - val_loss: 12.1652 - val_accuracy: 0.0428\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9767 - accuracy: 0.5422 - val_loss: 12.5059 - val_accuracy: 0.0412\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9693 - accuracy: 0.5484 - val_loss: 12.7826 - val_accuracy: 0.0481\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 985us/step - loss: 0.9615 - accuracy: 0.5565 - val_loss: 13.0506 - val_accuracy: 0.0529\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9529 - accuracy: 0.5646 - val_loss: 13.2944 - val_accuracy: 0.0830\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9461 - accuracy: 0.5652 - val_loss: 13.5822 - val_accuracy: 0.0576\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9389 - accuracy: 0.5775 - val_loss: 13.8245 - val_accuracy: 0.0481\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9318 - accuracy: 0.5775 - val_loss: 14.0782 - val_accuracy: 0.0497\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 981us/step - loss: 0.9265 - accuracy: 0.5793 - val_loss: 14.2748 - val_accuracy: 0.0581\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.5779 - val_loss: 14.7434 - val_accuracy: 0.0729\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 982us/step - loss: 0.9141 - accuracy: 0.5801 - val_loss: 14.8873 - val_accuracy: 0.0703\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 960us/step - loss: 0.9085 - accuracy: 0.5906 - val_loss: 15.2143 - val_accuracy: 0.0624\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 981us/step - loss: 0.9034 - accuracy: 0.5857 - val_loss: 15.4668 - val_accuracy: 0.0518\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 965us/step - loss: 0.9029 - accuracy: 0.5787 - val_loss: 15.7173 - val_accuracy: 0.0856\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 984us/step - loss: 0.8947 - accuracy: 0.5892 - val_loss: 15.9963 - val_accuracy: 0.0788\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 971us/step - loss: 0.8922 - accuracy: 0.5931 - val_loss: 16.2121 - val_accuracy: 0.0576\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8877 - accuracy: 0.5900 - val_loss: 16.5700 - val_accuracy: 0.0613\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 965us/step - loss: 0.8839 - accuracy: 0.5940 - val_loss: 16.8214 - val_accuracy: 0.0544\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8793 - accuracy: 0.5952 - val_loss: 17.0643 - val_accuracy: 0.0592\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 970us/step - loss: 0.8774 - accuracy: 0.5910 - val_loss: 17.3890 - val_accuracy: 0.0497\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 947us/step - loss: 0.8732 - accuracy: 0.5899 - val_loss: 17.5661 - val_accuracy: 0.0640\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8705 - accuracy: 0.5949 - val_loss: 17.7934 - val_accuracy: 0.0671\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 972us/step - loss: 0.8671 - accuracy: 0.5994 - val_loss: 18.1266 - val_accuracy: 0.0666\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 962us/step - loss: 0.8651 - accuracy: 0.5961 - val_loss: 18.4934 - val_accuracy: 0.0539\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 955us/step - loss: 0.8626 - accuracy: 0.5974 - val_loss: 18.6544 - val_accuracy: 0.0544\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 955us/step - loss: 0.8589 - accuracy: 0.6043 - val_loss: 18.9701 - val_accuracy: 0.0830\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8592 - accuracy: 0.5943 - val_loss: 19.1667 - val_accuracy: 0.0856\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 975us/step - loss: 0.8550 - accuracy: 0.6007 - val_loss: 19.4711 - val_accuracy: 0.0835\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 967us/step - loss: 0.8539 - accuracy: 0.5974 - val_loss: 19.6646 - val_accuracy: 0.0703\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 957us/step - loss: 0.8511 - accuracy: 0.6018 - val_loss: 20.0205 - val_accuracy: 0.0571\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 958us/step - loss: 0.8514 - accuracy: 0.5984 - val_loss: 20.1854 - val_accuracy: 0.0846\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 957us/step - loss: 0.8491 - accuracy: 0.5972 - val_loss: 20.5743 - val_accuracy: 0.0687\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 959us/step - loss: 0.8468 - accuracy: 0.6007 - val_loss: 20.7612 - val_accuracy: 0.0772\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 960us/step - loss: 0.8452 - accuracy: 0.5997 - val_loss: 21.0699 - val_accuracy: 0.0777\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 959us/step - loss: 0.8445 - accuracy: 0.5968 - val_loss: 21.3040 - val_accuracy: 0.0592\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 969us/step - loss: 0.8418 - accuracy: 0.6034 - val_loss: 21.5145 - val_accuracy: 0.0587\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 943us/step - loss: 0.8415 - accuracy: 0.5992 - val_loss: 21.7611 - val_accuracy: 0.0555\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.6002 - val_loss: 21.9762 - val_accuracy: 0.0666\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 973us/step - loss: 0.8372 - accuracy: 0.6050 - val_loss: 22.2854 - val_accuracy: 0.0513\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 977us/step - loss: 0.8389 - accuracy: 0.6022 - val_loss: 22.5920 - val_accuracy: 0.0650\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 968us/step - loss: 0.8359 - accuracy: 0.5992 - val_loss: 22.8533 - val_accuracy: 0.0840\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 965us/step - loss: 0.8340 - accuracy: 0.6074 - val_loss: 23.1374 - val_accuracy: 0.0640\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 972us/step - loss: 0.8349 - accuracy: 0.6027 - val_loss: 23.4146 - val_accuracy: 0.0777\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 974us/step - loss: 0.8325 - accuracy: 0.6044 - val_loss: 23.6633 - val_accuracy: 0.0650\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 997us/step - loss: 0.8317 - accuracy: 0.6035 - val_loss: 23.7954 - val_accuracy: 0.0661\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 961us/step - loss: 0.8314 - accuracy: 0.6056 - val_loss: 23.9653 - val_accuracy: 0.0629\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 975us/step - loss: 0.8299 - accuracy: 0.5997 - val_loss: 24.4113 - val_accuracy: 0.0809\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 959us/step - loss: 0.8284 - accuracy: 0.6075 - val_loss: 24.4818 - val_accuracy: 0.0756\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8268 - accuracy: 0.6114 - val_loss: 24.7883 - val_accuracy: 0.0539\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 973us/step - loss: 0.8280 - accuracy: 0.6017 - val_loss: 24.9276 - val_accuracy: 0.0608\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 971us/step - loss: 0.8272 - accuracy: 0.6018 - val_loss: 25.3215 - val_accuracy: 0.0846\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 941us/step - loss: 0.8262 - accuracy: 0.6052 - val_loss: 25.4709 - val_accuracy: 0.0740\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 950us/step - loss: 0.8256 - accuracy: 0.6055 - val_loss: 25.7265 - val_accuracy: 0.0761\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 946us/step - loss: 0.8245 - accuracy: 0.6022 - val_loss: 25.9167 - val_accuracy: 0.0677\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 940us/step - loss: 0.8243 - accuracy: 0.6054 - val_loss: 26.3891 - val_accuracy: 0.0856\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 947us/step - loss: 0.8253 - accuracy: 0.5997 - val_loss: 26.5204 - val_accuracy: 0.0856\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 953us/step - loss: 0.8238 - accuracy: 0.6029 - val_loss: 26.7836 - val_accuracy: 0.0809\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 939us/step - loss: 0.8222 - accuracy: 0.6033 - val_loss: 26.8273 - val_accuracy: 0.0624\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 954us/step - loss: 0.8234 - accuracy: 0.6006 - val_loss: 27.2832 - val_accuracy: 0.0708\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 951us/step - loss: 0.8218 - accuracy: 0.6068 - val_loss: 27.4456 - val_accuracy: 0.0809\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 952us/step - loss: 0.8227 - accuracy: 0.5982 - val_loss: 27.7622 - val_accuracy: 0.0856\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 978us/step - loss: 0.8198 - accuracy: 0.6036 - val_loss: 27.9258 - val_accuracy: 0.0740\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 955us/step - loss: 0.8208 - accuracy: 0.6009 - val_loss: 28.1126 - val_accuracy: 0.0735\n",
      "Epoch 79/100\n",
      "237/237 [==============================] - 0s 946us/step - loss: 0.8191 - accuracy: 0.6036 - val_loss: 28.4414 - val_accuracy: 0.0629\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 947us/step - loss: 0.8213 - accuracy: 0.5953 - val_loss: 28.5908 - val_accuracy: 0.0560\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 955us/step - loss: 0.8193 - accuracy: 0.6040 - val_loss: 28.7897 - val_accuracy: 0.0592\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 946us/step - loss: 0.8184 - accuracy: 0.6022 - val_loss: 29.2236 - val_accuracy: 0.0856\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 941us/step - loss: 0.8184 - accuracy: 0.6040 - val_loss: 29.3303 - val_accuracy: 0.0624\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 0.8196 - accuracy: 0.5984 - val_loss: 29.3693 - val_accuracy: 0.0846\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 936us/step - loss: 0.8176 - accuracy: 0.6044 - val_loss: 29.6814 - val_accuracy: 0.0555\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 969us/step - loss: 0.8198 - accuracy: 0.5984 - val_loss: 29.9455 - val_accuracy: 0.0745\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 946us/step - loss: 0.8168 - accuracy: 0.6066 - val_loss: 30.0806 - val_accuracy: 0.0740\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 937us/step - loss: 0.8169 - accuracy: 0.6043 - val_loss: 30.3300 - val_accuracy: 0.0840\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 954us/step - loss: 0.8170 - accuracy: 0.5998 - val_loss: 30.4110 - val_accuracy: 0.0629\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 943us/step - loss: 0.8159 - accuracy: 0.6027 - val_loss: 30.6388 - val_accuracy: 0.0613\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 936us/step - loss: 0.8157 - accuracy: 0.6064 - val_loss: 30.9404 - val_accuracy: 0.0640\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 950us/step - loss: 0.8182 - accuracy: 0.6003 - val_loss: 31.0208 - val_accuracy: 0.0856\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 939us/step - loss: 0.8156 - accuracy: 0.6063 - val_loss: 31.1074 - val_accuracy: 0.0777\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 953us/step - loss: 0.8154 - accuracy: 0.6043 - val_loss: 31.3975 - val_accuracy: 0.0793\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 949us/step - loss: 0.8148 - accuracy: 0.6059 - val_loss: 31.5001 - val_accuracy: 0.0576\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 945us/step - loss: 0.8148 - accuracy: 0.6059 - val_loss: 31.7185 - val_accuracy: 0.0698\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 939us/step - loss: 0.8143 - accuracy: 0.6043 - val_loss: 31.8077 - val_accuracy: 0.0698\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 979us/step - loss: 0.8146 - accuracy: 0.6011 - val_loss: 31.8893 - val_accuracy: 0.0687\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 944us/step - loss: 0.8145 - accuracy: 0.6080 - val_loss: 32.2112 - val_accuracy: 0.0729\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 938us/step - loss: 0.8139 - accuracy: 0.6043 - val_loss: 32.3544 - val_accuracy: 0.0708\n",
      "296/296 [==============================] - 0s 680us/step - loss: 7.1238 - accuracy: 0.5014\n",
      "Test accuracy: 0.5013747811317444\n",
      "296/296 [==============================] - 0s 616us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming you have features_tensor and labels_tensor ready\n",
    "\n",
    "# Determine input_shape\n",
    "input_shape = features_tensor.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(input_shape,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),        # Hidden layer with 128 neurons and ReLU activation\n",
    "    keras.layers.Dense(6, activation='softmax')  # Output layer with 'num_classes' and softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',  # You can use different optimizers like 'adam', 'SGD', etc.\n",
    "              loss='sparse_categorical_crossentropy',  # For multi-categorical classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(features_tensor, labels_tensor, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(features_tensor, labels_tensor)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(features_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
